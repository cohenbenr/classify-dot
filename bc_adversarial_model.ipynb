{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --quiet fuzzywuzzy gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "#import torchtext\n",
    "\n",
    "from validation.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.model import StarSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.adv_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_test(l_batch, r_batch, neg_batch):\n",
    "    global nan_break\n",
    "    \n",
    "    l_test = np.isnan(np.mean(l_batch.detach().cpu().numpy()))\n",
    "    r_test = np.isnan(np.mean(r_batch.detach().cpu().numpy()))\n",
    "    neg_test = np.isnan(np.mean(neg_batch.detach().cpu().numpy()))\n",
    "    if l_test or r_test or neg_test:\n",
    "        nan_break = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "SOC_LEVEL = 3\n",
    "OUTPUT_WEIGHTS = 'data/separation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(fmt=\"%(asctime)s %(levelname)s: %(message)s\", \n",
    "                          datefmt=\"%Y-%m-%d - %H:%M:%S\")\n",
    "fh = logging.FileHandler(\"adversarial_model.log\", \"w\")\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Pulling Indeed data for sample size %s' % SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job ads data\n",
    "indeed = get_indeed_texts('../data/us/everything.csv',use_gcs=True,nrows=SAMPLE_SIZE)\n",
    "indeed = indeed['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = indeed.copy()\n",
    "del indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DOT classifications data\n",
    "dot, dot_labs = dot_train_data(SOC_LEVEL)\n",
    "\n",
    "dot = dot.reset_index(drop=True)\n",
    "dot_labs = dot_labs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('About to train vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(d_embed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.train_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4152"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedder.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Trained Vocab of size %s' % str(len(embedder.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the file\n",
    "with open(OUTPUT_WEIGHTS + 'train_vocab_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(embedder.vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StarSpaceAdv()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StarSpaceAdv(\n",
    "    input_embedder = embedder,\n",
    "    k_neg = 10)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = embedder.get_positions(train)\n",
    "dot_positions = embedder.get_positions(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_pos)):\n",
    "    for j in range(len(train_pos[i])):\n",
    "        train_pos[i][j] = train_pos[i][j].to(device)\n",
    "\n",
    "for i in range(len(dot_positions)):\n",
    "    for j in range(len(dot_positions[i])):\n",
    "        dot_positions[i][j] = dot_positions[i][j].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "epochs = 3\n",
    "print_every = 1\n",
    "log_every = 1\n",
    "batch_size = 100\n",
    "\n",
    "#Losses\n",
    "losses = []\n",
    "epoch_losses = [1e12]\n",
    "log.info('Beginning run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation = torch.randperm(len(train_pos)).numpy()\n",
    "# nan_break = False\n",
    "# i = 0\n",
    "# indices = permutation[i:i+batch_size]\n",
    "# batch = train_pos[indices]\n",
    "# l_batch, r_batch, neg_batch = model(batch)\n",
    "\n",
    "# discriminator = LogisticRegression(100,2)\n",
    "# discriminator.to(device)\n",
    "\n",
    "# opt2 = torch.optim.Adam(discriminator.parameters(), lr=.01)\n",
    "\n",
    "# losses = []\n",
    "# for i in range(0,1000, batch_size):\n",
    "#         indices = permutation[i:i+batch_size]\n",
    "#         batch = train_pos[indices]\n",
    "#         l_batch, r_batch, neg_batch = model(batch)\n",
    "\n",
    "#         idx = torch.tensor(np.random.choice(dot_positions.shape[0], 100, False)).to(device)\n",
    "#         disc_dot = dot_positions[torch.nonzero(idx).detach().cpu()]\n",
    "#         dot_emb = [model.embed_doc(torch.cat(doc.tolist()[0])) for doc in disc_dot]\n",
    "#         dot_emb = torch.stack(dot_emb).to(device)\n",
    "#         disc_X = torch.cat([l_batch.squeeze(1), dot_emb], 0).to(device)\n",
    "#         disc_y = torch.cat([torch.zeros(100),torch.ones(100)],0).type(torch.LongTensor).to(device)\n",
    "\n",
    "#         opt2.zero_grad()\n",
    "#         disc_out = discriminator(disc_X)\n",
    "#         loss = criterion(disc_out,disc_y)\n",
    "#         loss.backward(retain_graph=True)\n",
    "#         opt2.step()\n",
    "        \n",
    "#         losses.append(loss.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-b9080f1fb250>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-b9080f1fb250>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    asdlfjalsdfj!\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#break cell\n",
    "asdlfjalsdfj!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert non-cpu tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-23936a081b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert non-cpu tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "model.embedder.weights.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-123b7c7e7487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_WEIGHTS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'weights_best_epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "weights = model.embedder.weights\n",
    "with open(OUTPUT_WEIGHTS + 'weights_best_epoch', 'wb') as f:\n",
    "    pickle.dump(weights.data.detach().cpu().numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star avg loss: 24539544.0\n",
      "star avg loss: 23264274.0\n",
      "star avg loss: 20416952.0\n",
      "star avg loss: 18061060.0\n",
      "star avg loss: 18256716.0\n",
      "star avg loss: 17743540.0\n",
      "star avg loss: 16363587.0\n",
      "star avg loss: 15986549.0\n",
      "star avg loss: 15781394.0\n",
      "Finished epoch 0 at Wed Jun 24 14:49:25 2020.\n",
      "best epoch so far!\n",
      "[1000000000000.0, 15781394.0]\n",
      "star avg loss: 14147595.0\n",
      "star avg loss: 13882734.0\n",
      "star avg loss: 13495282.0\n",
      "star avg loss: 13643106.0\n",
      "star avg loss: 12619786.0\n",
      "star avg loss: 12651068.0\n",
      "star avg loss: 12672415.0\n",
      "star avg loss: 12956690.0\n",
      "star avg loss: 12385585.0\n",
      "Finished epoch 1 at Wed Jun 24 14:49:30 2020.\n",
      "best epoch so far!\n",
      "[1000000000000.0, 15781394.0, 12385585.0]\n",
      "star avg loss: 12671940.0\n",
      "star avg loss: 12781222.0\n",
      "star avg loss: 13202035.0\n",
      "star avg loss: 13463298.0\n",
      "star avg loss: 13331326.0\n",
      "star avg loss: 12956054.0\n",
      "star avg loss: 12599894.0\n",
      "star avg loss: 11775056.0\n",
      "star avg loss: 11524094.0\n",
      "Finished epoch 2 at Wed Jun 24 14:49:35 2020.\n",
      "best epoch so far!\n",
      "[1000000000000.0, 15781394.0, 12385585.0, 11524094.0]\n"
     ]
    }
   ],
   "source": [
    "#Real loop\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(len(train_pos)).numpy()\n",
    "    nan_break = False\n",
    "    \n",
    "    for i in range(0,len(train), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch = train_pos[indices]\n",
    "\n",
    "        ###### Forward Pass- StarSpace #############################################################\n",
    "        model.train(); model.opt.zero_grad()\n",
    "        \n",
    "        l_batch, r_batch, neg_batch = model(batch)\n",
    "        \n",
    "        #Test for nans\n",
    "#         if nan_test(l_batch, r_batch, neg_batch):\n",
    "#             break\n",
    "        \n",
    "        positive_similarity = torch.bmm(l_batch,r_batch.transpose(2,1))\n",
    "        negative_similarity = torch.bmm(l_batch, neg_batch.transpose(2,1)).squeeze(1)\n",
    "\n",
    "        star_loss = torch.sum(torch.clamp(.1 - positive_similarity + negative_similarity, min=0))\n",
    "                \n",
    "        loss = star_loss\n",
    "\n",
    "        loss.backward(); model.opt.step()\n",
    "\n",
    "        ###### Print/Log #############################################################################\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        if (i % (print_every*batch_size) == 0) & (i > 0):\n",
    "            print('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "        if (i % (log_every*batch_size) == 0) & (i > 0):\n",
    "            log.info('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "    \n",
    "    # End of inner loop\n",
    "    if nan_break:\n",
    "        print(\"you've got nans\")\n",
    "        log.warning(\"you've got nans\")\n",
    "        break\n",
    "    \n",
    "    ###### Print/Log #############################################################################\n",
    "    print('Finished epoch %s at %s.' % (epoch,time.ctime()))\n",
    "    log.info(\"Finished epoch %s\" % str(epoch))\n",
    "    \n",
    "    epoch_loss = np.mean(losses[-int(SAMPLE_SIZE/batch_size):])\n",
    "\n",
    "    if (epoch_loss < min(epoch_losses)) | (len(epoch_losses) == 0):\n",
    "        print('best epoch so far!')\n",
    "        log.info('best epoch so far!')\n",
    "        \n",
    "        weights = model.embedder.weights.weight\n",
    "        with open(OUTPUT_WEIGHTS + 'weights_best_epoch', 'wb') as f:\n",
    "            pickle.dump(weights.data.detach().cpu().numpy(), f)\n",
    "    \n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.embeddings.weight\n",
    "with open(OUTPUT_WEIGHTS + 'weights_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(weights.data.detach().cpu().numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('You made it!')\n",
    "log.info('You made it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the weights to CSV\n",
    "# weights = model.input_embedding.weight\n",
    "# weights = weights.data.detach().numpy()\n",
    "# np.savetxt(\"weights_%s.csv\" % SAMPLE_SIZE, weights, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
