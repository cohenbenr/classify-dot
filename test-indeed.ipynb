{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet fuzzywuzzy\n",
    "! pip install --quiet diskcache\n",
    "! pip install --quiet python-Levenshtein\n",
    "! pip install --quiet lightgbm\n",
    "! pip install --quiet lime\n",
    "# ! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet torch\n",
    "! pip install --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import attr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import vstack \n",
    "\n",
    "from validation.data import indeed_test_data, dot_train_data, get_soc_n\n",
    "from embed_software.preprocess import *\n",
    "from embed_software.utils import get_embeddings, embed_docs\n",
    "from validation.dot_data import LemmaTokenizer, get_dictionary\n",
    "from classification.embedding import PreEmbeddedVectorizer, Embedding, WordEmbeddingVectorizer\n",
    "from validation.scoring import bubbleup_score, BubbleUpMixin\n",
    "\n",
    "pd.set_option('max_colwidth',50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 500000\n",
    "SOC_LEVEL = 3\n",
    "BUBBLE_UP = 2\n",
    "PROD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data(SOC_LEVEL)\n",
    "X_test, y_test, ids = indeed_test_data('../data/us/everything.csv', SAMPLE_SIZE, SOC_LEVEL)\n",
    "if PROD == False:\n",
    "    noprod_idx = get_soc_n(y_train.astype(str), 2) != 51\n",
    "    X_train, y_train = X_train[noprod_idx], y_train[noprod_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lookup = {val:i for i,val in enumerate(y_train.sort_values().unique())}\n",
    "labels = np.array([lookup[code] for code in y_train])\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "dbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "# bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(lookup.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def embed(tokenizer, model, X):\n",
    "    ids = [tokenizer.encode(x, max_length=512) for x in X]\n",
    "    masks = pad_sequence([torch.ones(len(idx)) for idx in ids], batch_first=True)\n",
    "    idss = [torch.tensor(i) for i in ids]\n",
    "    idss = pad_sequence(idss, batch_first=True)\n",
    "    dataset = TensorDataset(idss, masks)\n",
    "\n",
    "    \n",
    "    pooled = [model(x, attention_mask=m)[0][:,0].detach() \n",
    "              for x,m in DataLoader(dataset, batch_size=64)]\n",
    "\n",
    "    return torch.cat(pooled).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xt_test = embed(tokenizer, dbert, X_test[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class BubbleUpLogisticRegression(BubbleUpMixin, LogisticRegression):\n",
    "    pass\n",
    "\n",
    "models = [\n",
    "    Pipeline([('sentencespace_100_indeed', PreEmbeddedVectorizer('../indeed-embeds/model', cache_dir='indeed_embed_cache')),\n",
    "              ('lr', BubbleUpLogisticRegression(C=2., solver='lbfgs', class_weight='balanced', multi_class=\"multinomial\", n_jobs=-1).set_bubbles(BUBBLE_UP))]),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=2., solver='lbfgs', class_weight='balanced', multi_class='multinomial', n_jobs=-1)\n",
    "\n",
    "model.fit(Xt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.164"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(Xt_test, y_test[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preds = [model.predict(X_test) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546626603778631"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(get_soc_n(y_test.astype(str), 2).astype(str), preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrices(models, preds, y, SOC_LEVEL, prod):\n",
    "    dot_dict = get_dictionary('', SOC_LEVEL)\n",
    "    model_names = ['-'.join(m.named_steps.keys()) for m in models]\n",
    "    un = dot_dict.groupby('soc').apply(lambda df: df.head(1))\n",
    "    category_names = un['desc_soc{}'.format(SOC_LEVEL)]\n",
    "    for name,p in zip(model_names, preds):\n",
    "        df = pd.DataFrame(confusion_matrix(y, p, un.soc.astype(str)), \n",
    "                          index=category_names, \n",
    "                          columns=category_names)\n",
    "        filename = f'confusion-matrices/soc-{SOC_LEVEL}/{prod}/{name}.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "print_confusion_matrices(models, \n",
    "                         preds, \n",
    "                         get_soc_n(y_test.astype(str), BUBBLE_UP).astype(str), \n",
    "                         BUBBLE_UP, \n",
    "                         'withprod' if PROD else 'noprod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from validation.data import make_desc_lookup\n",
    "\n",
    "def _get_soc_n(df, n):\n",
    "    return (df.T\n",
    "            .reset_index()\n",
    "            .pipe(lambda df: df.assign(soc = df['index'].map(lambda i: str(i)[0:n])))\n",
    "            .set_index('soc')\n",
    "            .drop('index', 1)\n",
    "            .groupby('soc').sum().T)\n",
    "\n",
    "\n",
    "def get_pred(model, X):\n",
    "    vals = model.predict_proba(X)\n",
    "    df = pd.DataFrame(vals)\n",
    "    df.columns = model.classes_\n",
    "    n=3\n",
    "    return _get_soc_n(df, n)\n",
    "\n",
    "def run_lime(lookup, doc):\n",
    "    classes = get_pred(model, doc).columns.tolist()\n",
    "\n",
    "    explainer = LimeTextExplainer(class_names = classes)\n",
    "    exp = explainer.explain_instance(doc, lambda X: get_pred(model, X).values, num_features=10, top_labels=3)\n",
    "\n",
    "    for label in exp.available_labels():\n",
    "        print(classes[label], lookup(classes[label]))\n",
    "\n",
    "    return exp\n",
    "\n",
    "\n",
    "lookup = make_desc_lookup('', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "\n",
    "idx = np.random.choice(X_test.index)\n",
    "\n",
    "\n",
    "# idx = 87583\n",
    "\n",
    "print(idx)\n",
    "\n",
    "run_lime(lookup, X_test[idx]).show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68147, 1246, 17258, 82942, 22706, 99539, 6491)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "68147, 1246, 82942, 22706, 99539, 6491, 88072, 91587, 61655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "examples = [68147, 99539, 61655, 70538, 1246]\n",
    "\n",
    "for i in examples:\n",
    "    run_lime(lookup, X_test[i]).save_to_file(f'lime/lime-example-{i}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "test-indeed.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
