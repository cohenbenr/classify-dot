{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet fuzzywuzzy\n",
    "! pip install --quiet nltk\n",
    "! pip install --quiet diskcache\n",
    "! pip install --quiet python-Levenshtein\n",
    "! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from embed_software.preprocess import *\n",
    "from embed_software.utils import *\n",
    "from validation.title_matching import layered_matcher, title_matcher, punct_lookup, exact_matcher\n",
    "from dot_data import get_dictionary, LemmaTokenizer\n",
    "\n",
    "pd.set_option('max_colwidth',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_indeed_texts(path, **kwargs):\n",
    "    \"\"\"Reads csv with indeed data that turns into test set\"\"\"\n",
    "    indeed = pd.read_csv(path, **kwargs)\n",
    "    indeed['description'] = indeed.description.str.replace('Job Summary ', '')\n",
    "    indeed['title'] = indeed.title.str.lower()\n",
    "    return indeed\n",
    "\n",
    "def get_soc2(socs):\n",
    "    return socs.str.split('-').map(lambda a: a[0]).astype(int)\n",
    "\n",
    "def make_matcher():\n",
    "    \"\"\"Returns function that matches titles to SOC code\"\"\"\n",
    "    lookup = pd.read_csv('classify_dot/crosswalks/soc-title-lookup.csv')    \n",
    "    matcher = layered_matcher([\n",
    "        exact_matcher(lookup), \n",
    "        title_matcher(lookup, punct_lookup(lookup))\n",
    "    ])\n",
    "    return matcher\n",
    "\n",
    "def indeed_test_data(texts, lim):\n",
    "    \"\"\"Make test data from indeed (pre-embedded)\"\"\"\n",
    "    indeed = get_indeed_texts(texts, nrows=lim)\n",
    "    matcher = make_matcher()\n",
    "    matches = matcher(indeed.reset_index()).set_index('index')    \n",
    "    processor = Preprocessor(readme_processor, 1, 1, 6).process\n",
    "    descriptions = matches.description.map(processor)     \n",
    "    return matches.description, get_soc2(matches.code) \n",
    "\n",
    "class PreEmbeddedVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, embed_path, model, lim):\n",
    "        self.embed_path = embed_path\n",
    "        self.model = model\n",
    "        self.lim = lim\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_X = X\n",
    "        self.embeddings = get_embeddings(self.embed_path, self.lim)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Our test set is pre-embedded, but our train set not!\n",
    "        # This should simply be a cached embedding...? \n",
    "        if self.fit_X is X:\n",
    "            return embed_docs(self.model, '\\n'.join(X))\n",
    "        else:\n",
    "            return self.embeddings[X.index] \n",
    "            \n",
    "\n",
    "def dot_train_data():\n",
    "    \"\"\"Combine DOT Dictionary and Tasks descriptions for training set\"\"\"   \n",
    "\n",
    "    dot_dict = get_dictionary('classify_dot')\n",
    "    tasks = pd.read_csv('classify_dot/tasks.txt', sep='\\t')\n",
    "    processor = Preprocessor(readme_processor, 1, 1, 6).process\n",
    "    X_train = pd.concat([dot_dict.job_description, tasks.Task]).map(processor)    \n",
    "    y_train = pd.concat([dot_dict.soc2, get_soc2(tasks['O*NET-SOC Code'])])\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = [\n",
    "    Pipeline([('tfidf', pd.read_pickle('classify_dot/models/tfidf.pkl')),\n",
    "              ('lr', pd.read_pickle('classify_dot/models/logistic-model.pkl'))]),\n",
    "    Pipeline([('tfidf', TfidfVectorizer()),\n",
    "              ('lr', LogisticRegression(solver=\"newton-cg\", multi_class=\"multinomial\", n_jobs=-1))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('ss_embeds/ss_100.txt', 'ss_models/sentencespace', SAMPLE_SIZE)),\n",
    "             ('lr', LogisticRegression(solver=\"newton-cg\", multi_class=\"multinomial\", n_jobs=-1))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('ss_embeds/ss_100.txt', 'ss_models/sentencespace', SAMPLE_SIZE)),\n",
    "             ('knn', KNeighborsClassifier(7))]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data()\n",
    "X_test, y_test = indeed_test_data('everything.csv', SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [m.fit(X_train, y_train).predict(X_test) for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46138278345178141,\n",
       " 0.47079587706499743,\n",
       " 0.43380241916505857,\n",
       " 0.42716618816774132]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(p, y_test) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         11       0.42      0.35      0.38      3273\n",
      "         13       0.32      0.50      0.39      2650\n",
      "         15       0.68      0.61      0.64      6479\n",
      "         17       0.31      0.49      0.38       929\n",
      "         19       0.39      0.22      0.28       457\n",
      "         21       0.13      0.25      0.17       217\n",
      "         23       1.00      0.16      0.28        56\n",
      "         25       0.51      0.56      0.53       442\n",
      "         27       0.71      0.45      0.55      2635\n",
      "         29       0.67      0.51      0.58       821\n",
      "         31       0.22      0.17      0.19        65\n",
      "         33       0.05      0.04      0.04       134\n",
      "         35       0.87      0.38      0.53       291\n",
      "         37       0.69      0.12      0.21       166\n",
      "         39       0.31      0.29      0.30       133\n",
      "         41       0.37      0.46      0.41       967\n",
      "         43       0.18      0.28      0.22       722\n",
      "         45       0.00      0.00      0.00        17\n",
      "         47       0.25      0.18      0.21       157\n",
      "         49       0.03      0.31      0.05        29\n",
      "         51       0.24      0.12      0.16       517\n",
      "         53       0.08      0.24      0.12        71\n",
      "         55       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.51      0.46      0.47     21247\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         11       0.40      0.37      0.38      3273\n",
      "         13       0.35      0.55      0.43      2650\n",
      "         15       0.78      0.54      0.64      6479\n",
      "         17       0.38      0.51      0.43       929\n",
      "         19       0.48      0.23      0.31       457\n",
      "         21       0.24      0.02      0.04       217\n",
      "         23       0.86      0.11      0.19        56\n",
      "         25       0.44      0.60      0.51       442\n",
      "         27       0.56      0.57      0.57      2635\n",
      "         29       0.62      0.62      0.62       821\n",
      "         31       0.50      0.02      0.03        65\n",
      "         33       0.60      0.07      0.12       134\n",
      "         35       0.94      0.37      0.53       291\n",
      "         37       0.83      0.03      0.06       166\n",
      "         39       0.36      0.25      0.29       133\n",
      "         41       0.37      0.43      0.40       967\n",
      "         43       0.20      0.28      0.23       722\n",
      "         45       0.00      0.00      0.00        17\n",
      "         47       0.28      0.20      0.24       157\n",
      "         49       0.07      0.24      0.11        29\n",
      "         51       0.10      0.27      0.15       517\n",
      "         53       0.39      0.21      0.28        71\n",
      "         55       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.53      0.47      0.48     21247\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         11       0.54      0.11      0.19      3273\n",
      "         13       0.54      0.30      0.38      2650\n",
      "         15       0.77      0.59      0.67      6479\n",
      "         17       0.30      0.45      0.36       929\n",
      "         19       0.47      0.34      0.39       457\n",
      "         21       0.49      0.11      0.17       217\n",
      "         23       0.64      0.45      0.53        56\n",
      "         25       0.33      0.59      0.42       442\n",
      "         27       0.54      0.55      0.54      2635\n",
      "         29       0.55      0.68      0.61       821\n",
      "         31       0.33      0.14      0.20        65\n",
      "         33       0.27      0.17      0.21       134\n",
      "         35       0.75      0.75      0.75       291\n",
      "         37       0.90      0.11      0.19       166\n",
      "         39       0.14      0.59      0.22       133\n",
      "         41       0.30      0.52      0.38       967\n",
      "         43       0.23      0.25      0.24       722\n",
      "         45       0.00      0.00      0.00        17\n",
      "         47       0.15      0.27      0.19       157\n",
      "         49       0.04      0.38      0.07        29\n",
      "         51       0.07      0.48      0.12       517\n",
      "         53       0.11      0.30      0.16        71\n",
      "         55       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.56      0.43      0.45     21247\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         11       0.41      0.25      0.31      3273\n",
      "         13       0.47      0.33      0.39      2650\n",
      "         15       0.70      0.58      0.63      6479\n",
      "         17       0.28      0.40      0.33       929\n",
      "         19       0.35      0.41      0.38       457\n",
      "         21       0.42      0.13      0.20       217\n",
      "         23       0.59      0.41      0.48        56\n",
      "         25       0.35      0.61      0.44       442\n",
      "         27       0.72      0.39      0.50      2635\n",
      "         29       0.57      0.69      0.62       821\n",
      "         31       0.13      0.11      0.12        65\n",
      "         33       0.17      0.07      0.10       134\n",
      "         35       0.75      0.75      0.75       291\n",
      "         37       0.63      0.10      0.18       166\n",
      "         39       0.20      0.53      0.29       133\n",
      "         41       0.33      0.45      0.38       967\n",
      "         43       0.25      0.24      0.24       722\n",
      "         45       0.00      0.00      0.00        17\n",
      "         47       0.12      0.16      0.14       157\n",
      "         49       0.08      0.38      0.13        29\n",
      "         51       0.06      0.43      0.11       517\n",
      "         53       0.20      0.24      0.22        71\n",
      "         55       0.67      0.11      0.18        19\n",
      "\n",
      "avg / total       0.52      0.43      0.45     21247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for p in preds:\n",
    "    print(classification_report(y_test, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "test-indeed.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
