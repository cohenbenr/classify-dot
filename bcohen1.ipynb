{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ! pip install --quiet seaborn toolz fuzzywuzzy\n",
    "#  ! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import InnerProductSimilarity, MarginRankingLoss, StarSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100000\n",
    "SOC_LEVEL = 2\n",
    "BUBBLE_UP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indeed_texts(path, use_gcs = False, **kwargs):\n",
    "    \"\"\"Reads csv with indeed data that turns into test set\"\"\"\n",
    "    if use_gcs:\n",
    "        fs = GCSFileSystem(project='labor-market-data')\n",
    "        path = path.replace('..','lmd-classify-dot',1)\n",
    "        with fs.open(path) as f:\n",
    "            indeed = pd.read_csv(f, **kwargs)\n",
    "    else:\n",
    "        indeed = pd.read_csv(path, **kwargs)\n",
    "\n",
    "    indeed['title'] = indeed.title.str.lower()\n",
    "    return indeed\n",
    "\n",
    "def indeed_test_data(texts, lim, soc_n, use_gcs = False):\n",
    "    \"\"\"Make test data from indeed (pre-embedded)\"\"\"\n",
    "    indeed = get_indeed_texts(texts, use_gcs, nrows=lim)\n",
    "    matcher = make_matcher()\n",
    "    matches = matcher(indeed.reset_index()).set_index('index')\n",
    "    return matches.content, get_soc_n(matches.code, soc_n), matches.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    part time temporary do you have or know someon...\n",
       "1    40 000 46 000 year lead electrician minimum ye...\n",
       "2    front desk position chiropractic office monday...\n",
       "3    110 000 130 000 year job title sec reporting m...\n",
       "4    internship avakas is unique place where ideas ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_indeed_texts('../data/us/everything.csv',use_gcs=True,nrows=1000)\n",
    "train = train['content']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(train, min_ct = 2):\n",
    "    ''' build vocabulary for an array/list/series of text '''\n",
    "    # To do: smaller groups before aggregating to improve performance\n",
    "    def wordcount_df(doc):\n",
    "        tok = doc.split()\n",
    "        d = pd.DataFrame.from_dict(Counter(tok),orient='index').reset_index().rename(columns={'index':'word'})\n",
    "        return d\n",
    "\n",
    "    d_list = [wordcount_df(x) for x in train]\n",
    "\n",
    "    d = pd.concat(d_list,axis=0)\n",
    "\n",
    "    d = d.groupby(['word'])[0].sum().sort_values(ascending=False)\n",
    "    d = d[d >= min_ct]\n",
    "    \n",
    "    d = dict(zip(d.index.values, range(len(d))))\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter, val_iter = data.BucketIterator.splits(\n",
    "#     (train, validation), batch_size=batch_size, device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarSpace(\n",
    "    d_embed=100,\n",
    "    vocabulary=train_vocab,\n",
    "    n_input=len(train_vocab),\n",
    "    similarity=InnerProductSimilarity(),\n",
    "    max_norm=20,\n",
    "    aggregate=torch.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01\n",
    "criterion = MarginRankingLoss(margin=1., aggregate=torch.mean)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train[0:100]\n",
    "validation = train[100:150]\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lhs = batch.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding = nn.Embedding(num_embeddings=len(train_vocab), embedding_dim = 100, max_norm=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## negative similarity\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_batch = torch.stack(l_batch)\n",
    "r_batch = torch.stack(r_batch)\n",
    "neg_batch = torch.stack(neg_batch)\n",
    "\n",
    "l_batch = l_batch.unsqueeze(1)\n",
    "r_batch = r_batch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_similarity = torch.bmm(l_batch,r_batch.transpose(2,1)) #this is the same as dot product by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_similarity = torch.bmm(l_batch, neg_batch.transpose(2,1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(torch.clamp(.1 - positive_similarity + negative_similarity, min=0))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward(); opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy of predictions in current batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_rhs = torch.autograd.Variable(torch.arange(0, 100).long().expand(100, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_doc(d,vocab,embedding,normalize=False):\n",
    "#     positions = []\n",
    "#     for t in d:\n",
    "#         try:\n",
    "#             positions.append(vocab[t])\n",
    "#         except KeyError:\n",
    "#             pass\n",
    "#     output = torch.sum(embedding(torch.LongTensor(positions)),dim=0)\n",
    "#     if normalize:\n",
    "#         output = output / output.norm()\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # similarity\n",
    "# l_batch = []\n",
    "# r_batch = []\n",
    "# neg_batch = []\n",
    "\n",
    "# for i in range(len(batch)):\n",
    "#     #Positive similarity\n",
    "#     s = batch.values[i].split('\\t') #sentences\n",
    "#     if type(s) == str: #only one sentence in s\n",
    "#         a = s\n",
    "#         b = s\n",
    "#     else:\n",
    "#         a, b = np.random.choice(s, 2, False)\n",
    "    \n",
    "#     a = a.split()\n",
    "#     b = b.split()\n",
    "    \n",
    "#     a_emb = embed_doc(a,train_vocab,input_embedding,normalize=True)\n",
    "#     b_emb = embed_doc(b,train_vocab,input_embedding,normalize=True)\n",
    "    \n",
    "#     l_batch.append(a_emb)\n",
    "#     r_batch.append(b_emb)\n",
    "\n",
    "#     #Negative similarity\n",
    "#     negs = []\n",
    "#     for _i in range(k * 3):\n",
    "#         index = np.random.choice(len(batch))\n",
    "#         if not index == i: #if it's not from the same document\n",
    "#             c = batch.values[index].split('\\t')\n",
    "#             c = np.random.choice(c, 1)[0].split()\n",
    "#             c_emb = embed_doc(c,train_vocab,input_embedding,normalize=True)\n",
    "#             negs.append(c_emb)\n",
    "#             if(len(negs) >= k):\n",
    "#                 break\n",
    "    \n",
    "#     neg_batch.append(torch.stack(negs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
