{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from scipy.sparse import vstack \n",
    "\n",
    "from validation.data import *\n",
    "from validation.scoring import bubbleup_score, BubbleUpMixin\n",
    "\n",
    "from src.model import StarSpace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100000 #500000\n",
    "SOC_LEVEL = 6\n",
    "BUBBLE_UP = 3\n",
    "PROD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data(SOC_LEVEL)\n",
    "X_test, y_test, ids = indeed_test_data('../data/us/everything.csv', SAMPLE_SIZE, SOC_LEVEL, use_gcs=True)\n",
    "if PROD == False:\n",
    "    noprod_idx = get_soc_n(y_train.astype(str), 2) != 51\n",
    "    X_train, y_train = X_train[noprod_idx], y_train[noprod_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    performs as nonspeaking member of scene in sta...\n",
       "1    directs and coordinates through subordinate su...\n",
       "2    circumcises jewish male infants in accordance ...\n",
       "3    researches plans designs and administers build...\n",
       "4    designs and oversees construction and repair o...\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8881, 100)\n"
     ]
    }
   ],
   "source": [
    "# path = 'lmd-classify-dot/ss-models/bcohen/weights_e5'\n",
    "# fs = GCSFileSystem(project='labor-market-data')\n",
    "# with fs.open(path) as f:\n",
    "#     embeddings = pickle.load(f)\n",
    "\n",
    "with open('data/separation/weights_10000', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(embeddings.shape)\n",
    "embeddings = torch.FloatTensor(embeddings)\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'lmd-classify-dot/ss-models/bcohen/train_vocab_e5'\n",
    "# fs = GCSFileSystem(project='labor-market-data')\n",
    "# with fs.open(path) as f:\n",
    "#     vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/separation/train_vocab_10000', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarSpace(\n",
    "    d_embed=100,\n",
    "    vocabulary=vocab,\n",
    "    k_neg = 10,\n",
    "    input_embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = model.get_positions(X_train)\n",
    "X_test = model.get_positions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7283744812011719\n",
      "2.638395071029663\n"
     ]
    }
   ],
   "source": [
    "X_train_emb = np.empty([X_train.shape[0],100])\n",
    "X_test_emb = np.empty([X_test.shape[0],100])\n",
    "\n",
    "start_time = time.time()\n",
    "for i,doc in enumerate(X_train):\n",
    "    X_train_emb[i] = model.embed_doc(torch.cat(doc))\n",
    "print(time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "for i,doc in enumerate(X_test):\n",
    "    X_test_emb[i] = model.embed_doc(torch.cat(doc))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BubbleUpLogisticRegression(BubbleUpMixin, LogisticRegression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BubbleUpLogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           l1_ratio=None, max_iter=100,\n",
       "                           multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
       "                           random_state=None, solver='lbfgs', tol=0.0001,\n",
       "                           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bubbles = BubbleUpLogisticRegression(C=2., solver='lbfgs', class_weight='balanced', \n",
    "                                     multi_class=\"multinomial\", n_jobs=-1).set_bubbles(BUBBLE_UP)\n",
    "\n",
    "Bubbles.fit(X_train_emb,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Bubbles.predict(X_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1013003261986684"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(get_soc_n(y_test.astype(str), BUBBLE_UP).astype(str), y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2641951678592624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "davies_bouldin_score(X_train_emb,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
