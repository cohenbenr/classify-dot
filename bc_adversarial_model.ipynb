{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, davies_bouldin_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#import torchtext\n",
    "\n",
    "from validation.data import *\n",
    "\n",
    "from src.model import StarSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(fmt=\"%(asctime)s %(levelname)s: %(message)s\", \n",
    "                          datefmt=\"%Y-%m-%d - %H:%M:%S\")\n",
    "fh = logging.FileHandler(\"adversarial_model.log\", \"w\")\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 10000\n",
    "SOC_LEVEL = 3\n",
    "OUTPUT_WEIGHTS = 'data/adversarial/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Pulling Indeed data for sample size %s' % SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job ads data\n",
    "indeed = get_indeed_texts('../data/us/everything.csv',use_gcs=True,nrows=SAMPLE_SIZE)\n",
    "indeed = indeed['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = indeed.copy()\n",
    "del indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DOT classifications data\n",
    "dot, dot_labs = dot_train_data(SOC_LEVEL)\n",
    "\n",
    "dot.reset_index(drop=True,inplace=True)\n",
    "dot_labs.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('About to train vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = CountVectorizer(min_df = 5,\n",
    "                             max_df = .99)\n",
    "Vectorizer.fit(train)\n",
    "\n",
    "train_vocab = Vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Trained Vocab of size %s' % str(len(train_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the file\n",
    "with open(OUTPUT_WEIGHTS + 'train_vocab_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(train_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(OUTPUT_WEIGHTS + \"train_vocab_%s\" % SAMPLE_SIZE,\"rb\") as f:\n",
    "#     train_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarSpace(\n",
    "    d_embed=100,\n",
    "    vocabulary=train_vocab,\n",
    "    k_neg = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34404, 100)\n"
     ]
    }
   ],
   "source": [
    "#Starting from the separation model\n",
    "with open('data/separation/train_vocab_200000', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "with open('data/separation/weights_200000', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(embeddings.shape)\n",
    "embeddings = torch.FloatTensor(embeddings)\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "\n",
    "model = StarSpace(\n",
    "    d_embed=100,\n",
    "    vocabulary=vocab,\n",
    "    k_neg = 10,\n",
    "    input_embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = LogisticRegression(solver='lbfgs', class_weight='balanced', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_sample_size = 10000\n",
    "dindex = int(.9 * disc_sample_size)\n",
    "\n",
    "dot_sample = dot.sample(disc_sample_size).reset_index(drop=True)\n",
    "train_sample = train.sample(disc_sample_size).reset_index(drop=True)\n",
    "\n",
    "dot_emb = np.empty([dot_sample.shape[0],100])\n",
    "train_emb = np.empty([dot_sample.shape[0],100])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(len(dot_sample)):\n",
    "        doc = dot_sample[j].replace('\\t',' ').split(' ')\n",
    "        dot_emb[j] = model.embed_doc(doc)\n",
    "        \n",
    "        doc = train[j].replace('\\t',' ').split(' ')\n",
    "        train_emb[j] = model.embed_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_X_train = np.vstack([dot_emb[:dindex,:], train_emb[:dindex,:]])\n",
    "disc_X_test = np.vstack([dot_emb[dindex:,:], train_emb[dindex:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_y_train = np.hstack([np.zeros(dindex),np.ones(dindex)])\n",
    "disc_y_test = np.hstack([np.zeros(disc_sample_size-dindex),np.ones(disc_sample_size-dindex)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.fit(disc_X_train,disc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = discriminator.predict(disc_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(disc_y_test,y_pred) #.98 with random embeddings, .81 with separation model- ways to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "print_every = 10\n",
    "log_every = 10\n",
    "batch_size = 100\n",
    "\n",
    "dot_sample = dot\n",
    "dot_y_sample = dot_labs\n",
    "\n",
    "losses = []\n",
    "separation_losses = []\n",
    "epoch_losses = [1e10]\n",
    "log.info('Beginning run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(len(train)).numpy()\n",
    "    nan_break = False\n",
    "    \n",
    "    for i in range(0,len(train), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch = train[indices]\n",
    "\n",
    "        model.train(); opt.zero_grad()\n",
    "\n",
    "        lhs = batch.values\n",
    "\n",
    "        l_batch, r_batch, neg_batch = model(lhs)\n",
    "        # nan tests...\n",
    "        l_test = np.isnan(np.mean(l_batch.detach().numpy()))\n",
    "        r_test = np.isnan(np.mean(r_batch.detach().numpy()))\n",
    "        neg_test = np.isnan(np.mean(neg_batch.detach().numpy()))\n",
    "        \n",
    "        if l_test or r_test or neg_test:\n",
    "            nan_break = True\n",
    "            break\n",
    "        \n",
    "        positive_similarity = torch.bmm(l_batch,r_batch.transpose(2,1)) #this is the same as dot product by row\n",
    "\n",
    "        negative_similarity = torch.bmm(l_batch, neg_batch.transpose(2,1)).squeeze(1)\n",
    "\n",
    "        star_loss = torch.sum(torch.clamp(.1 - positive_similarity + negative_similarity, min=0))\n",
    "        \n",
    "        # Now add in clustering loss for DOT categories\n",
    "#         dot_sample = dot.sample(frac=.5)\n",
    "#         dot_y_sample = dot_labs[dot_sample.index]\n",
    "        dot_emb = np.empty([dot_sample.shape[0],100])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for j,doc in enumerate(dot_sample):\n",
    "                s = doc.replace('\\t',' ').split(' ')\n",
    "                dot_emb[j] = model.embed_doc(s)\n",
    "            \n",
    "        separation_loss = torch.tensor(davies_bouldin_score(dot_emb,dot_y_sample) * 1000000)\n",
    "        separation_loss.requires_grad = True\n",
    "        \n",
    "        loss = star_loss + separation_loss\n",
    "        \n",
    "        losses.append(star_loss.detach().numpy())\n",
    "        separation_losses.append(separation_loss.detach().numpy())\n",
    "\n",
    "        loss.backward(); opt.step()\n",
    "        \n",
    "        if i % (print_every*batch_size) == 0:\n",
    "            print('separation avg loss: %s' % str(np.mean(separation_losses[-10:])))\n",
    "            print('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "        if i % (log_every*batch_size) == 0:\n",
    "            log.info('separation avg loss: %s' % str(np.mean(separation_losses[-10:])))\n",
    "            log.info('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "    \n",
    "    # End of inner loop\n",
    "    if nan_break:\n",
    "        print(\"you've got nans\")\n",
    "        log.warning(\"you've got nans\")\n",
    "        break\n",
    "    \n",
    "    print('Finished epoch %s at %s.' % (epoch,time.ctime()))\n",
    "    log.info(\"Finished epoch %s\" % str(epoch))\n",
    "    \n",
    "    epoch_loss = np.mean(losses[(len(losses)-100):])\n",
    "    \n",
    "    if epoch_loss < min(epoch_losses):\n",
    "        print('best epoch so far!')\n",
    "        log.info('best epoch so far!')\n",
    "        \n",
    "        weights = model.embeddings.weight\n",
    "        with open(OUTPUT_WEIGHTS + 'weights_best_epoch', 'wb') as f:\n",
    "            pickle.dump(weights.data.detach().numpy(), f)\n",
    "    \n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.embeddings.weight\n",
    "with open(OUTPUT_WEIGHTS + 'weights_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(weights.data.detach().numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('You made it!')\n",
    "log.info('You made it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the weights to CSV\n",
    "# weights = model.input_embedding.weight\n",
    "# weights = weights.data.detach().numpy()\n",
    "# np.savetxt(\"weights_%s.csv\" % SAMPLE_SIZE, weights, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for j in range(0,len(valid), batch_size):\n",
    "#     valperm = torch.randperm(len(valid)).numpy()\n",
    "#     val_indices = valperm[j:j+batch_size]\n",
    "#     val_batch = valid[val_indices]\n",
    "\n",
    "#     val_lhs = val_batch.values\n",
    "\n",
    "#     val_l_batch, val_r_batch, val_neg_batch = model(val_lhs)\n",
    "\n",
    "#     val_positive_similarity = torch.bmm(val_l_batch,val_r_batch.transpose(2,1))\n",
    "#     val_negative_similarity = torch.bmm(val_l_batch, val_neg_batch.transpose(2,1)).squeeze(1)\n",
    "\n",
    "#     val_loss = torch.sum(torch.clamp(.1 - val_positive_similarity + val_negative_similarity, min=0))\n",
    "#     if j % (print_every*batch_size) == 0:\n",
    "#         print(val_loss)\n",
    "    \n",
    "#     val_accuracy_check = val_positive_similarity.squeeze(1) > val_negative_similarity[:,0].unsqueeze(1)\n",
    "#     val_acc += np.sum(val_accuracy_check.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val_acc/len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def build_vocab(train, min_ct = 2):\n",
    "#     ''' build vocabulary for an array/list/series of text '''\n",
    "#     # To do: smaller groups before aggregating to improve performance\n",
    "#     def wordcount_df(doc):\n",
    "#         tok = doc.split()\n",
    "#         d = pd.DataFrame.from_dict(Counter(tok),orient='index').reset_index().rename(columns={'index':'word'})\n",
    "#         return d\n",
    "\n",
    "#     d_list = [wordcount_df(x) for x in train]\n",
    "\n",
    "#     d = pd.concat(d_list,axis=0)\n",
    "\n",
    "#     d = d.groupby(['word'])[0].sum().sort_values(ascending=False)\n",
    "#     d = d[d >= min_ct]\n",
    "    \n",
    "#     d = dict(zip(d.index.values, range(len(d))))\n",
    "    \n",
    "#     return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = train[0:100]\n",
    "# validation = train[100:150]\n",
    "# batch_size = 100\n",
    "\n",
    "# model.train()\n",
    "# opt.zero_grad()\n",
    "\n",
    "# lhs = batch.values\n",
    "\n",
    "# l_batch, r_batch, neg_batch = model(lhs)\n",
    "\n",
    "# positive_similarity = torch.bmm(l_batch,r_batch.transpose(2,1)) #this is the same as dot product by row\n",
    "\n",
    "# negative_similarity = torch.bmm(l_batch, neg_batch.transpose(2,1)).squeeze(1)\n",
    "\n",
    "# loss = torch.mean(torch.clamp(.1 - positive_similarity + negative_similarity, min=0))\n",
    "# loss\n",
    "\n",
    "# loss.backward(); opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy of predictions in current batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_check = positive_similarity.squeeze(1) > negative_similarity[:,0].unsqueeze(1)\n",
    "# acc = np.mean(similarity_check.detach().numpy())\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_doc(d,vocab,embedding,normalize=False):\n",
    "#     positions = []\n",
    "#     for t in d:\n",
    "#         try:\n",
    "#             positions.append(vocab[t])\n",
    "#         except KeyError:\n",
    "#             pass\n",
    "#     output = torch.sum(embedding(torch.LongTensor(positions)),dim=0)\n",
    "#     if normalize:\n",
    "#         output = output / output.norm()\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # similarity\n",
    "# l_batch = []\n",
    "# r_batch = []\n",
    "# neg_batch = []\n",
    "\n",
    "# for i in range(len(batch)):\n",
    "#     #Positive similarity\n",
    "#     s = batch.values[i].split('\\t') #sentences\n",
    "#     if type(s) == str: #only one sentence in s\n",
    "#         a = s\n",
    "#         b = s\n",
    "#     else:\n",
    "#         a, b = np.random.choice(s, 2, False)\n",
    "    \n",
    "#     a = a.split()\n",
    "#     b = b.split()\n",
    "    \n",
    "#     a_emb = embed_doc(a,train_vocab,input_embedding,normalize=True)\n",
    "#     b_emb = embed_doc(b,train_vocab,input_embedding,normalize=True)\n",
    "    \n",
    "#     l_batch.append(a_emb)\n",
    "#     r_batch.append(b_emb)\n",
    "\n",
    "#     #Negative similarity\n",
    "#     negs = []\n",
    "#     for _i in range(k * 3):\n",
    "#         index = np.random.choice(len(batch))\n",
    "#         if not index == i: #if it's not from the same document\n",
    "#             c = batch.values[index].split('\\t')\n",
    "#             c = np.random.choice(c, 1)[0].split()\n",
    "#             c_emb = embed_doc(c,train_vocab,input_embedding,normalize=True)\n",
    "#             negs.append(c_emb)\n",
    "#             if(len(negs) >= k):\n",
    "#                 break\n",
    "    \n",
    "#     neg_batch.append(torch.stack(negs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
