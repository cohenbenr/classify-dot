{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet fuzzywuzzy\n",
    "! pip install --quiet nltk\n",
    "! pip install --quiet diskcache\n",
    "! pip install --quiet python-Levenshtein\n",
    "! pip install --quiet lightgbm\n",
    "! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import attr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from embed_software.preprocess import *\n",
    "from embed_software.utils import *\n",
    "from validation.title_matching import layered_matcher, title_matcher, punct_lookup, exact_matcher\n",
    "from validation.dot_data import LemmaTokenizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import vstack \n",
    "from validation.data import indeed_test_data, dot_train_data\n",
    "\n",
    "pd.set_option('max_colwidth',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class PreEmbeddedVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, embed_path, model, lim, dims):\n",
    "        self.embed_path = embed_path\n",
    "        self.model = model\n",
    "        self.lim = lim\n",
    "        self.dims = dims\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_X = X\n",
    "        self.embeddings = get_embeddings(self.embed_path, self.lim, self.dims)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Our test set is pre-embedded, but our train set not!\n",
    "        # This should simply be a cached embedding...? \n",
    "        if self.fit_X is X:\n",
    "            return embed_docs(self.model, '\\n'.join(X))\n",
    "        else:\n",
    "            return self.embeddings[X.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100000\n",
    "SOC_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data(SOC_LEVEL)\n",
    "X_test, y_test, ids = indeed_test_data('us-everything.csv', SAMPLE_SIZE, SOC_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class VectorizedData():\n",
    "    def __init__(self, vectorizer, splits, n_jobs):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = splits\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def vectorize(self):\n",
    "        self.V_train = self.vectorizer.fit_transform(self.X_train)\n",
    "        self.V_test = self.vectorizer.transform(self.X_test)\n",
    "        \n",
    "    def top_n_results(self, search, n=5):\n",
    "        res = search.cv_results_\n",
    "        tops = np.flip(np.argsort(res['mean_test_score']), 0)[:5]\n",
    "        scores = np.array(res['mean_test_score'])[tops]\n",
    "        params = pd.DataFrame(np.array(res['params'])[tops].tolist())\n",
    "        return params.assign(score = scores)\n",
    "\n",
    "    def run_search(self, model, param_grid):\n",
    "        y = pd.concat([self.y_train, self.y_test])\n",
    "        try:\n",
    "            X = np.concatenate([self.V_train, self.V_test])\n",
    "        except ValueError:\n",
    "            X = vstack([self.V_train, self.V_test]) \n",
    "        cv = [(np.arange(0, self.X_train.shape[0]), np.arange(self.X_train.shape[0], X.shape[0]))]\n",
    "        search = GridSearchCV(model, param_grid=param_grid, cv = cv, n_jobs=8)\n",
    "        search.fit(X, y)\n",
    "        return self.top_n_results(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "splits = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "ss_embedder = PreEmbeddedVectorizer('../ss_embeds/ss_100_us.txt', '../ss_models/sentencespace', SAMPLE_SIZE)\n",
    "embedded = VectorizedData(ss_embedder,splits, 8)\n",
    "embedded.vectorize()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow = VectorizedData(tfidf, splits, 8)\n",
    "bow.vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [9, 31],\n",
    "    'max_depth': [-1, 2],\n",
    "    'n_estimators': [100, 400]\n",
    "}\n",
    "\n",
    "embedded.run_search(LGBMClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C     score\n",
      "0  20.0  0.525174\n",
      "1  10.0  0.519633\n",
      "2   5.0  0.502294\n",
      "3   1.0  0.308884\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0, 20.0]\n",
    "}\n",
    "\n",
    "print(embedded.run_search(SVC(), param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C  multi_class     score\n",
      "0   5.0  multinomial  0.537747\n",
      "1  10.0  multinomial  0.537270\n",
      "2   1.0  multinomial  0.532444\n",
      "3  10.0          ovr  0.518620\n",
      "4   5.0          ovr  0.517786\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0],\n",
    "    'multi_class': ['multinomial', 'ovr']\n",
    "}\n",
    "\n",
    "print(embedded.run_search(LogisticRegression(solver='newton-cg'), param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C  multi_class     score\n",
      "0   5.0          ovr  0.489900\n",
      "1  10.0          ovr  0.483287\n",
      "2   5.0  multinomial  0.475958\n",
      "3   1.0          ovr  0.469761\n",
      "4   1.0  multinomial  0.469582\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0],\n",
    "    'multi_class': ['multinomial', 'ovr']\n",
    "}\n",
    "\n",
    "print(bow.run_search(LogisticRegression(solver='newton-cg'), param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# COMPARE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    Pipeline([('tfidf', TfidfVectorizer()),\n",
    "              ('lr', LogisticRegression(C=5., solver='newton-cg', multi_class=\"ovr\", n_jobs=-1))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us_b.txt', '../ss_models/sentencespace_us', SAMPLE_SIZE, 100)),\n",
    "             ('lr', LogisticRegression(C=5., solver='newton-cg', multi_class=\"multinomial\", n_jobs=-1))]),\n",
    "#     Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us.txt', '../ss_models/sentencespace', SAMPLE_SIZE)),\n",
    "#              ('knn', KNeighborsClassifier(7))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us_b.txt', '../ss_models/sentencespace_us', SAMPLE_SIZE, 100)),\n",
    "             ('svc', SVC(C=20., probability=True))]),\n",
    "#     Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us.txt', '../ss_models/sentencespace', SAMPLE_SIZE)),\n",
    "#              ('lgbm', LGBMClassifier(n_estimators=400, max_depth=2))])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Predictor():\n",
    "    X_train = attr.ib()\n",
    "    y_train = attr.ib()\n",
    "    X_test = attr.ib()\n",
    "\n",
    "    def fn(self, m):\n",
    "        return (m\n",
    "                .fit(self.X_train, self.y_train)\n",
    "                .predict(self.X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = Predictor(X_train, y_train, X_test)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor as Pool\n",
    "\n",
    "pool = Pool()\n",
    "preds = pool.map(p.fn, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preds = [p for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48990049454805457, 0.5673598283977834, 0.5657510576178275]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(p, y_test) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(preds).T.assign(y = y_test.values)\n",
    "\n",
    "differ = p[p[0] != p[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "differ[differ[0] == differ['y']].y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          11       0.71      0.21      0.32      4534\n",
      "          13       0.54      0.49      0.51      3119\n",
      "          15       0.75      0.75      0.75      2641\n",
      "          17       0.54      0.66      0.59       439\n",
      "          19       0.12      0.39      0.19        85\n",
      "          21       0.26      0.34      0.30        96\n",
      "          23       0.09      0.73      0.15        11\n",
      "          25       0.56      0.60      0.58       315\n",
      "          27       0.45      0.54      0.49      1309\n",
      "          29       0.64      0.52      0.57      1269\n",
      "          31       0.03      0.95      0.06        19\n",
      "          33       0.11      0.56      0.19        16\n",
      "          35       0.52      0.92      0.67       704\n",
      "          37       0.21      0.47      0.29        40\n",
      "          39       0.30      0.57      0.39       222\n",
      "          41       0.27      0.64      0.38       435\n",
      "          43       0.31      0.54      0.39       937\n",
      "          45       0.00      0.00      0.00        37\n",
      "          47       0.33      0.43      0.38        86\n",
      "          49       0.28      0.40      0.33        57\n",
      "          51       0.26      0.35      0.30       288\n",
      "          53       0.25      0.73      0.38       124\n",
      "          55       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     16783\n",
      "   macro avg       0.33      0.51      0.36     16783\n",
      "weighted avg       0.58      0.49      0.49     16783\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds[0], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          11       0.28      0.45      0.35       806\n",
      "          13       0.60      0.66      0.63      2567\n",
      "          15       0.84      0.73      0.78      3029\n",
      "          17       0.73      0.40      0.52       999\n",
      "          19       0.25      0.20      0.22       339\n",
      "          21       0.40      0.38      0.39       130\n",
      "          23       0.67      0.70      0.69        88\n",
      "          25       0.60      0.43      0.50       478\n",
      "          27       0.46      0.60      0.52      1227\n",
      "          29       0.75      0.53      0.62      1441\n",
      "          31       0.30      0.72      0.42       234\n",
      "          33       0.36      0.30      0.33        97\n",
      "          35       0.89      0.84      0.86      1315\n",
      "          37       0.34      0.86      0.49        36\n",
      "          39       0.68      0.39      0.49       750\n",
      "          41       0.60      0.57      0.59      1092\n",
      "          43       0.37      0.57      0.44      1042\n",
      "          45       0.10      0.04      0.06        26\n",
      "          47       0.59      0.29      0.39       224\n",
      "          49       0.52      0.54      0.53        79\n",
      "          51       0.42      0.32      0.36       493\n",
      "          53       0.52      0.65      0.58       284\n",
      "          55       0.19      0.43      0.26         7\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     16783\n",
      "   macro avg       0.50      0.50      0.48     16783\n",
      "weighted avg       0.63      0.59      0.59     16783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds[1], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dot_dict = get_dictionary('', SOC_LEVEL)\n",
    "un = dot_dict.groupby('soc').apply(lambda df: df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_names = ['-'.join(m.named_steps.keys()) for m in models]\n",
    "category_names = un['desc_soc{}'.format(SOC_LEVEL)]\n",
    "for name,p in zip(model_names, preds):\n",
    "    df = pd.DataFrame(confusion_matrix(y_test, p, un.soc), \n",
    "                      index=category_names, \n",
    "                      columns=category_names)\n",
    "    df.to_csv('confusion-matrices/soc-{}/{}.csv'.format(SOC_LEVEL, name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "test-indeed-2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
