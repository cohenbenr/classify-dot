{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet fuzzywuzzy\n",
    "! pip install --quiet nltk\n",
    "! pip install --quiet diskcache\n",
    "! pip install --quiet python-Levenshtein\n",
    "! pip install --quiet lightgbm\n",
    "! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "embeds = pd.read_csv('../ss_models/sentencespace.tsv', sep = '\\t', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "embeds.abs().sum(1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4cdc6c3ebf04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m from .least_angle import (Lars, LassoLars, lars_path, LarsCV, LassoLarsCV,\n\u001b[1;32m     16\u001b[0m                           LassoLarsIC)\n\u001b[0;32m---> 17\u001b[0;31m from .coordinate_descent import (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                  \u001b[0mlasso_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiTaskLasso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                  \u001b[0mMultiTaskElasticNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiTaskElasticNetCV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvergenceWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcd_fast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/linear_model/cd_fast.pyx\u001b[0m in \u001b[0;36minit sklearn.linear_model.cd_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import attr\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import vstack \n",
    "\n",
    "from validation.data import indeed_test_data, dot_train_data, get_soc_n\n",
    "from embed_software.preprocess import *\n",
    "from embed_software.utils import get_embeddings, embed_docs\n",
    "from validation.title_matching import layered_matcher, title_matcher, punct_lookup, exact_matcher\n",
    "from validation.dot_data import LemmaTokenizer, get_dictionary\n",
    "\n",
    "pd.set_option('max_colwidth',50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class PreEmbeddedVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, embed_path, model, lim, dims):\n",
    "        self.embed_path = embed_path\n",
    "        self.model = model\n",
    "        self.lim = lim\n",
    "        self.dims = dims\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_X = X\n",
    "        self.embeddings = get_embeddings(self.embed_path, self.lim, self.dims)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Our test set is pre-embedded, but our train set not!\n",
    "        # This should simply be a cached embedding...? \n",
    "        if self.fit_X is X:\n",
    "            return embed_docs(self.model, '\\n'.join(X))\n",
    "        else:\n",
    "            return self.embeddings[X.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100000\n",
    "SOC_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data(SOC_LEVEL)\n",
    "# X_test, y_test, ids = indeed_test_data('us-everything.csv', SAMPLE_SIZE, SOC_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vecs = PreEmbeddedVectorizer('../ss_embeds/ss_100_us_b.txt', '../ss_models/sentencespace_us', SAMPLE_SIZE, 100).fit_transform(X_train)\n",
    "dot_dict = get_dictionary('', SOC_LEVEL)\n",
    "vecs = vecs[:dot_dict.shape[0]]\n",
    "y_train = y_train[:dot_dict.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "desc = 'desc_soc{}'.format(SOC_LEVEL)\n",
    "\n",
    "lookup = dot_dict.groupby('soc').apply(lambda df: df.head(1))[['soc', desc]]\n",
    "y_desc = pd.DataFrame({ 'soc': y_train}).merge(lookup, how='left', on='soc')\n",
    "labels = y_desc[desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "occupations = np.random.choice(y_desc[desc].unique(), size=6, replace=False)\n",
    "idx = y_desc[y_desc[desc].isin(occupations)].groupby(desc).apply(lambda df: df.sample(100)).index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS, Isomap, TSNE\n",
    "two = MDS().fit_transform(vecs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(two, columns = ['x', 'y']).assign(Category = labels[idx].astype('category').values)\n",
    "ax = sns.scatterplot(x = 'x', y = 'y', hue = 'Category', data=df, s=100)\n",
    "ax.get_figure().savefig('figures/MDS-soc2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class VectorizedData():\n",
    "    def __init__(self, vectorizer, splits, n_jobs):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = splits\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def vectorize(self):\n",
    "        self.V_train = self.vectorizer.fit_transform(self.X_train)\n",
    "        self.V_test = self.vectorizer.transform(self.X_test)\n",
    "        \n",
    "    def top_n_results(self, search, n=5):\n",
    "        res = search.cv_results_\n",
    "        tops = np.flip(np.argsort(res['mean_test_score']), 0)[:5]\n",
    "        scores = np.array(res['mean_test_score'])[tops]\n",
    "        params = pd.DataFrame(np.array(res['params'])[tops].tolist())\n",
    "        return params.assign(score = scores)\n",
    "\n",
    "    def run_search(self, model, param_grid):\n",
    "        y = pd.concat([self.y_train, self.y_test])\n",
    "        try:\n",
    "            X = np.concatenate([self.V_train, self.V_test])\n",
    "        except ValueError:\n",
    "            X = vstack([self.V_train, self.V_test]) \n",
    "        cv = [(np.arange(0, self.X_train.shape[0]), np.arange(self.X_train.shape[0], X.shape[0]))]\n",
    "        search = GridSearchCV(model, param_grid=param_grid, cv = cv, n_jobs=8)\n",
    "        search.fit(X, y)\n",
    "        return self.top_n_results(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "splits = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "ss_embedder = PreEmbeddedVectorizer('../ss_embeds/ss_100_us.txt', '../ss_models/sentencespace', SAMPLE_SIZE)\n",
    "embedded = VectorizedData(ss_embedder,splits, 8)\n",
    "embedded.vectorize()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow = VectorizedData(tfidf, splits, 8)\n",
    "bow.vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [9, 31],\n",
    "    'max_depth': [-1, 2],\n",
    "    'n_estimators': [100, 400]\n",
    "}\n",
    "\n",
    "embedded.run_search(LGBMClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C     score\n",
      "0  20.0  0.525174\n",
      "1  10.0  0.519633\n",
      "2   5.0  0.502294\n",
      "3   1.0  0.308884\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0, 20.0]\n",
    "}\n",
    "\n",
    "print(embedded.run_search(SVC(), param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C  multi_class     score\n",
      "0   5.0  multinomial  0.537747\n",
      "1  10.0  multinomial  0.537270\n",
      "2   1.0  multinomial  0.532444\n",
      "3  10.0          ovr  0.518620\n",
      "4   5.0          ovr  0.517786\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0],\n",
    "    'multi_class': ['multinomial', 'ovr']\n",
    "}\n",
    "\n",
    "print(embedded.run_search(LogisticRegression(solver='newton-cg'), param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C  multi_class     score\n",
      "0   5.0          ovr  0.489900\n",
      "1  10.0          ovr  0.483287\n",
      "2   5.0  multinomial  0.475958\n",
      "3   1.0          ovr  0.469761\n",
      "4   1.0  multinomial  0.469582\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 5.0, 10.0],\n",
    "    'multi_class': ['multinomial', 'ovr']\n",
    "}\n",
    "\n",
    "print(bow.run_search(LogisticRegression(solver='newton-cg'), param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# COMPARE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    Pipeline([('tfidf', TfidfVectorizer()),\n",
    "              ('lr', LogisticRegression(C=5., solver='newton-cg', multi_class=\"ovr\", n_jobs=-1))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us_b.txt', '../ss_models/sentencespace_us', SAMPLE_SIZE, 100)),\n",
    "             ('lr', LogisticRegression(C=5., solver='newton-cg', multi_class=\"multinomial\", n_jobs=-1))]),\n",
    "#     Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us.txt', '../ss_models/sentencespace', SAMPLE_SIZE)),\n",
    "#              ('knn', KNeighborsClassifier(7))]),\n",
    "    Pipeline([('embed', PreEmbeddedVectorizer('../ss_embeds/ss_100_us_b.txt', '../ss_models/sentencespace_us', SAMPLE_SIZE, 100)),\n",
    "             ('svc', SVC(C=20., probability=True))]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Predictor():\n",
    "    X_train = attr.ib()\n",
    "    y_train = attr.ib()\n",
    "    X_test = attr.ib()\n",
    "\n",
    "    def fn(self, m):\n",
    "        return (m\n",
    "                .fit(self.X_train, self.y_train)\n",
    "                .predict(self.X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = Predictor(X_train, y_train, X_test)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor as Pool\n",
    "\n",
    "pool = Pool()\n",
    "preds = pool.map(p.fn, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preds = [p for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49040702886856735, 0.58729304883151034, 0.57982188751419517]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(p, y_test) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(preds).T.assign(y = y_test.values)\n",
    "\n",
    "differ = p[p[0] != p[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "differ[differ[0] == differ['y']].y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(preds[0], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(preds[1], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrices(models, preds, SOC_LEVEL):\n",
    "    dot_dict = get_dictionary('', SOC_LEVEL)\n",
    "    model_names = ['-'.join(m.named_steps.keys()) for m in models]\n",
    "    un = dot_dict.groupby('soc').apply(lambda df: df.head(1))\n",
    "    category_names = un['desc_soc{}'.format(SOC_LEVEL)]\n",
    "    for name,p in zip(model_names, preds):\n",
    "        df = pd.DataFrame(confusion_matrix(y_test, p, un.soc), \n",
    "                          index=category_names, \n",
    "                          columns=category_names)\n",
    "        filename = 'confusion-matrices/soc-{}/{}.csv'.format(SOC_LEVEL, name)\n",
    "        df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions_df(df, preds):\n",
    "    key = 'predicted_soc{}'.format(SOC_LEVEL)\n",
    "    desc = 'desc_soc{}'.format(SOC_LEVEL)\n",
    "    dot_dict = get_dictionary('', SOC_LEVEL)\n",
    "    dd = dot_dict.groupby('soc').first()[desc].reset_index()\n",
    "    found = (pd.DataFrame({key: preds})\n",
    "             .merge(dd, how='left', left_on=key, right_on='soc')\n",
    "             .drop('soc', 1))\n",
    "    return (pd.concat([df, found], 1)\n",
    "            .rename(columns = {'content': 'description'}))\n",
    "\n",
    "def print_predictions(model, infile, outpath, SOC_LEVEL):\n",
    "    X_train, y_train = dot_train_data(SOC_LEVEL)\n",
    "    df = pd.read_csv(infile)\n",
    "    all_preds = model.fit(X_train, y_train).predict(df.content)\n",
    "    filename = '{}/us-soc{}-predictions.csv'.format(outpath, SOC_LEVEL)\n",
    "    make_predictions_df(df, all_preds).to_csv(filename, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('confusion-matrices/soc-3/embed-lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41054341938978156, 0.40667660208643813)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19705964432013226, 0.19270635975295053)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46063510164916216, 0.40667660208643819)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro(df, 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "test-indeed.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
