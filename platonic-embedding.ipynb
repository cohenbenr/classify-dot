{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from validation.data import dot_train_data, get_soc_n, get_dictionary, indeed_test_data\n",
    "from embed_software.preprocess import *\n",
    "from embed_software.utils import get_embeddings, embed_docs\n",
    "from classification.embedding import PreEmbeddedVectorizer\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth',50)\n",
    "pd.set_option('display.width', 700)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100000\n",
    "SOC_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = dot_train_data(SOC_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "fs = GCSFileSystem(project='labor-market-data')\n",
    "with fs.open('lmd-classify-dot/data/us/company-everything.csv') as f:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "df['title'] = df.title.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_source(X_train, y_train):\n",
    "    for d,y in zip(X_train, y_train):\n",
    "        doc = embedding.embed_paragraph(d).T.reshape(1, 100, -1)\n",
    "        doc = torch.from_numpy(doc).float()\n",
    "        label = torch.tensor([y]).long()\n",
    "        yield doc, label\n",
    "\n",
    "def load_target(docs):\n",
    "    for d in docs:\n",
    "        doc = embedding.embed_paragraph(d).T.reshape(1, 100, -1)\n",
    "        doc = torch.from_numpy(doc).float()\n",
    "        yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Embedding():\n",
    "    def __init__(self, path):\n",
    "        embedding = pd.read_csv(path, sep='\\t', header=None)\n",
    "        keys = embedding.iloc[:,0]\n",
    "        vals = embedding.iloc[:,1:].values\n",
    "        self.lookup = {k:v for k,v in zip(keys, vals)}\n",
    "\n",
    "    def embed_paragraph(self, doc):\n",
    "        sents = doc.split('\\t')\n",
    "        vecs = [self.embed_sent(sent) for sent in sents]\n",
    "        vecs = [v for v in vecs if v is not None] # check if sentence is empty\n",
    "        return np.array(vecs)            \n",
    "\n",
    "    def embed_sent(self, sent):\n",
    "        vec = self.embed_doc(sent)\n",
    "        if len(vec):\n",
    "            return vec.sum(0) / np.linalg.norm(vec)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def embed_doc(self, doc, return_words = False):\n",
    "        words = []\n",
    "        vecs = []\n",
    "        for word in doc.split():\n",
    "            try:\n",
    "                vecs.append(self.lookup[word])\n",
    "                words.append(word)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if not return_words: \n",
    "            return np.array(vecs)\n",
    "        return np.array(vecs), words\n",
    "\n",
    "\n",
    "embedding = Embedding('../indeed-embeds/model.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "label_lookup = {v:k for k,v in pd.Series(y_train.unique()).to_dict().items()}\n",
    "y_train_idx = [label_lookup[y] for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "docs, labels = zip(*list(load_source(X_train, y_train_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(n=50000)\n",
    "target = list(load_target(df.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from toolz import curry\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, net, opt, criterion = None):\n",
    "        self.net = net\n",
    "        self.opt = opt(net)\n",
    "        self.criterion = criterion\n",
    "        self.net.register_backward_hook(printgradnorm)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.net(X).view(-1)\n",
    "\n",
    "    def evaluate(self, source, target, label):\n",
    "        out = self.__call__(source)\n",
    "        loss = self.criterion(out.reshape(1, -1), label)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class Discriminator(Classifier):\n",
    "    def evaluate(self, source, target, label):\n",
    "        guess_s = self.__call__(source)\n",
    "        guess_t = self.__call__(target)\n",
    "        loss = self.criterion(guess_s, torch.tensor([1.]))\n",
    "        loss += self.criterion(guess_t, torch.tensor([-1.]))\n",
    "        return loss\n",
    "        \n",
    "\n",
    "class PlatonicNet():\n",
    "    def __init__(self, embedder, classifier, discriminator, batch_size=64, n_epochs=5):\n",
    "        self.discriminator = discriminator\n",
    "        self.classifier = classifier\n",
    "        self.embedder = embedder\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.grad_norm_clip = 0.025\n",
    "\n",
    "    def load_data(self, docs, labels, target):\n",
    "        self.docs, self.labels, self.target = docs, labels, target.copy()\n",
    "\n",
    "    def batch(self, size):\n",
    "        random.shuffle(self.target)\n",
    "\n",
    "        dat = list(zip(self.docs, self.labels, self.target))\n",
    "        random.shuffle(dat)\n",
    "\n",
    "        out = []\n",
    "        while dat:\n",
    "            head,dat = dat[:size], dat[size:]\n",
    "            out.append(head)\n",
    "        return out\n",
    "\n",
    "    def epoch(self, embedder):\n",
    "        epoch_disc_loss = 0\n",
    "        epoch_class_loss = 0\n",
    "\n",
    "        for i,batch in enumerate(self.batch(self.batch_size)):\n",
    "            batch_disc_loss = 0\n",
    "            batch_class_loss = 0\n",
    "\n",
    "            # run for each net, classifier and discriminator\n",
    "            for net,sign in [(self.classifier, 1), (self.discriminator, -1)]:\n",
    "\n",
    "                # due to pytorch updating, \n",
    "                # run twice, once for embedder, once for the other model\n",
    "                for updating_model,sgn in [(embedder, sign), (net, 1)]:\n",
    "                    \n",
    "                    updating_model.opt.zero_grad()\n",
    "                    loss = 0\n",
    "                    for source, label, target in batch:\n",
    "                        loss += net.evaluate(embedder(source), embedder(target), label)\n",
    "                        if torch.isnan(loss):\n",
    "                            print(embedder(source))\n",
    "                            raise Exception('LOSS/EMBEDDING IS NAN')\n",
    "\n",
    "                    loss *= sign\n",
    "                    \n",
    "                    if sign < 0:\n",
    "                        batch_disc_loss += loss\n",
    "                        epoch_disc_loss += loss\n",
    "                    else:\n",
    "                        batch_class_loss += loss\n",
    "                        epoch_class_loss += loss\n",
    "                    loss.backward()\n",
    "\n",
    "                    torch.nn.utils.clip_grad_value_(updating_model.net.parameters(), self.grad_norm_clip)\n",
    "                    updating_model.opt.step()\n",
    "                    \n",
    "            if i % 100 == 0:\n",
    "                print(f'Batch class/disc loss: {batch_class_loss} ::: {batch_disc_loss}')\n",
    "        print(f'----------- EPOCH --------------\\nEpoch class/disc loss: {epoch_class_loss} ::: {epoch_disc_loss}')        \n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.epoch(self.embedder)            \n",
    "\n",
    "\n",
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    if grad_input[0].norm() > 600.:\n",
    "        print('grad_input norm:', grad_input[0].norm())\n",
    "\n",
    "class GatedNet(torch.nn.Module):\n",
    "    def __init__(self, embed_size, layers):\n",
    "        super().__init__()\n",
    "        self.conver = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embed_size, out_channels=layers, kernel_size=1, groups=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.conver.register_backward_hook(printgradnorm)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        convs = self.conver(x)\n",
    "        out = torch.matmul(x, torch.t(convs.max(1).values))\n",
    "        return out / torch.norm(out)  \n",
    "\n",
    "\n",
    "def _embedder(embed_size, layers):\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=embed_size, out_channels=layers, kernel_size=1, groups=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveMaxPool1d(output_size=1),\n",
    "        nn.Dropout(p=0.25)\n",
    "    )\n",
    "\n",
    "    net.register_backward_hook(printgradnorm)\n",
    "    return net    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 584.4098510742188 ::: -178.2403564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 552.3291015625 ::: -265.2200927734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 522.257080078125 ::: -308.1689453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 492.631591796875 ::: -406.66265869140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 457.7840881347656 ::: -423.6307678222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 260234.65625 ::: -168984.140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 459.88751220703125 ::: -410.251953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 441.5174865722656 ::: -478.87567138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 449.98187255859375 ::: -424.98779296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 437.3743896484375 ::: -447.0699157714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 414.9876403808594 ::: -479.4339904785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 447.04302978515625 ::: -426.9431457519531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 226395.015625 ::: -232739.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 391.5748291015625 ::: -508.047607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 450.5005798339844 ::: -465.57647705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 432.8442077636719 ::: -599.3541870117188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 435.601318359375 ::: -576.580810546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 429.64154052734375 ::: -543.239013671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 216763.84375 ::: -273864.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 405.45147705078125 ::: -567.2535400390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 392.1707763671875 ::: -557.09619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 427.6141357421875 ::: -523.069091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 395.3511047363281 ::: -670.39599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 421.0580139160156 ::: -615.4805908203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 448.6578369140625 ::: -611.7037353515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 211017.796875 ::: -308732.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 431.4724426269531 ::: -656.7446899414062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 422.68731689453125 ::: -628.1716918945312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 413.0703125 ::: -620.9329223632812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 424.67730712890625 ::: -682.7667236328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 428.7297058105469 ::: -637.4623413085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 410.93511962890625 ::: -717.5020141601562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 206739.25 ::: -341525.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 443.2616882324219 ::: -717.1974487304688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 442.01470947265625 ::: -800.630615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 429.6741638183594 ::: -598.8499145507812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 406.7196044921875 ::: -776.4276123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 403.8837890625 ::: -759.2978515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 446.21392822265625 ::: -717.7222900390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 203315.078125 ::: -371526.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 436.582763671875 ::: -808.15087890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 408.59527587890625 ::: -784.536376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 408.20733642578125 ::: -777.6864624023438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 404.8863525390625 ::: -766.2387084960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 435.57501220703125 ::: -703.7081909179688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 410.7972412109375 ::: -757.63134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 200458.375 ::: -403072.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 410.3885803222656 ::: -842.0288696289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 379.1239013671875 ::: -801.5884399414062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 399.40625 ::: -988.7857055664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 435.48345947265625 ::: -871.29052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 399.74017333984375 ::: -856.109130859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 338.1229553222656 ::: -924.7833251953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 198033.5625 ::: -432626.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 389.07373046875 ::: -894.3946533203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 397.10302734375 ::: -967.978271484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 421.25537109375 ::: -902.5859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 402.982421875 ::: -892.080322265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 386.44769287109375 ::: -945.206787109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 358.2181396484375 ::: -1074.4908447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 195903.65625 ::: -461215.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 355.67181396484375 ::: -848.8766479492188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 334.46270751953125 ::: -1090.366943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 341.178955078125 ::: -1016.0640258789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 395.705322265625 ::: -940.0366821289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 382.79364013671875 ::: -1103.3408203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 408.870361328125 ::: -1005.6273193359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EPOCH --------------\n",
      "Epoch class/disc loss: 194025.625 ::: -490319.90625\n"
     ]
    }
   ],
   "source": [
    "from adabound import AdaBound\n",
    "\n",
    "@curry\n",
    "def adam_opt(lr, net):\n",
    "    return optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "@curry\n",
    "def ab_opt(lr, net):\n",
    "    return AdaBound(net.parameters(), lr=lr, final_lr=0.01)\n",
    "\n",
    "n_classes = y_train.unique().shape[0]\n",
    "classifier = Classifier(nn.Sequential(nn.Linear(100, n_classes)), ab_opt(0.001), nn.CrossEntropyLoss())\n",
    "\n",
    "discriminator = Discriminator(nn.Sequential(nn.Linear(100, 1)), ab_opt(0.01), nn.SoftMarginLoss())\n",
    "\n",
    "embedder = Classifier(GatedNet(100, 50), ab_opt(0.0001))\n",
    "\n",
    "model = PlatonicNet(embedder, classifier, discriminator, n_epochs=10)\n",
    "\n",
    "model.load_data(docs, labels, target)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 381.31427001953125 ::: -786.635009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 379.6686706542969 ::: -1002.591064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 397.80194091796875 ::: -902.412353515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 402.3179016113281 ::: -1021.63134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 336.9195251464844 ::: -996.4227294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch class/disc loss: 431.1322937011719 ::: -1054.1578369140625\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model.embedder(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model-28.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.embedder.net.state_dict(), 'embedder-state-dict-28.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "list(model.embedder.net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15397196, 0.3561607)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 90\n",
    "\n",
    "def get_spread(d):\n",
    "    vals = model.embedder.net.conver(d).max(1).values.detach().numpy()\n",
    "    return vals.max() - vals.min()\n",
    "    \n",
    "\n",
    "np.mean([get_spread(d) for d in docs[:500]]), np.mean([get_spread(d) for d in target[:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "i = 44\n",
    "\n",
    "idx = np.where(model.embedder.net.conver(target[i]).max(1).values.detach().numpy() > .5)[1]\n",
    "np.array(df.content.iloc[i].split('\\t'))[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\nvalues=tensor([[0.4257, 0.5064, 0.4322, 0.4226, 0.5467, 0.4889, 0.3775, 0.3027, 0.4938,\n         0.4459, 0.1576, 0.3468, 0.4140, 0.4285]], grad_fn=<MinBackward0>),\nindices=tensor([[37, 37, 20, 37, 41, 17,  5,  6, 37,  6,  6,  6,  6, 37]]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedder.net.conver(target[12]).min(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from validation.scoring import bubbleup_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def simple_embed(doc):\n",
    "    X = doc.sum(2).reshape(-1)\n",
    "    return X / torch.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xe_train = [simple_embed(d).detach().numpy() for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852736225959305"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = LogisticRegression(C=1., n_jobs=-1, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(Xe_train, y_train)\n",
    "preds = clf.predict(Xe_train)\n",
    "accuracy_score(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xp_train = [model.embedder(d).detach().numpy() for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.486419523676794"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1., n_jobs=-1, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(Xp_train, y_train)\n",
    "preds = clf.predict(Xp_train)\n",
    "accuracy_score(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE=100000\n",
    "X_test, y_test, ids = indeed_test_data('../data/us/everything.csv', SAMPLE_SIZE, 6)\n",
    "X_train, y_train = dot_train_data(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xe_test = [model.embedder(d).detach().numpy() for d in load_target(X_test)]\n",
    "Xe_train = [model.embedder(d).detach().numpy() for d in load_target(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=-1, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=5., n_jobs=-1, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(Xe_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47129004870637653"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bubbleup_score(y_train, Xe_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xe_test = [simple_embed(d).detach().numpy() for d in load_target(X_test)]\n",
    "Xe_train = [simple_embed(d).detach().numpy() for d in load_target(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=-1, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=5., n_jobs=-1, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(Xe_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4752223066267483"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bubbleup_score(y_train, Xe_test, y_test, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "platonic-embedding.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
