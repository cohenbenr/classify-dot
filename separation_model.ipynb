{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -e 'git://github.com/nandanrao/embed-software.git#egg=embed_software'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --quiet fuzzywuzzy gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#import torchtext\n",
    "\n",
    "from validation.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import StarSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(fmt=\"%(asctime)s %(levelname)s: %(message)s\", \n",
    "                          datefmt=\"%Y-%m-%d - %H:%M:%S\")\n",
    "fh = logging.FileHandler(\"separation_model.log\", \"w\")\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 10000\n",
    "SOC_LEVEL = 3\n",
    "OUTPUT_WEIGHTS = 'data/separation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Pulling Indeed data for sample size %s' % SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job ads data\n",
    "indeed = get_indeed_texts('../data/us/everything.csv',use_gcs=True,nrows=SAMPLE_SIZE)\n",
    "indeed = indeed['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = indeed.copy()\n",
    "del indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DOT classifications data\n",
    "dot, dot_labs = dot_train_data(SOC_LEVEL)\n",
    "\n",
    "dot.reset_index(drop=True,inplace=True)\n",
    "dot_labs.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('About to train vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = CountVectorizer(min_df = 10,\n",
    "                             max_df = .99)\n",
    "Vectorizer.fit(train)\n",
    "\n",
    "train_vocab = Vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8881"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info('Trained Vocab of size %s' % str(len(train_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the file\n",
    "with open(OUTPUT_WEIGHTS + 'train_vocab_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(train_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start from file:\n",
    "# with open('data/separation/weights_100000', 'rb') as f:\n",
    "#     embeddings = pickle.load(f)\n",
    "\n",
    "# print(embeddings.shape)\n",
    "# embeddings = torch.FloatTensor(embeddings)\n",
    "# embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "\n",
    "# with open('data/separation/train_vocab_100000', 'rb') as f:\n",
    "#     vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarSpace(\n",
    "    d_embed=100,\n",
    "    vocabulary=train_vocab,\n",
    "    k_neg = 10)\n",
    "#     input_embedding = embeddings)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr = .01\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = model.get_positions(train)\n",
    "dot_positions = model.get_positions(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_pos)):\n",
    "    for j in range(len(train_pos[i])):\n",
    "        train_pos[i][j] = train_pos[i][j].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dot_positions)):\n",
    "    for j in range(len(dot_positions[i])):\n",
    "        dot_positions[i][j] = dot_positions[i][j].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_torch(X, labels):\n",
    "    n_cluster = len(set(labels))\n",
    "    cluster_vals = list(set(labels))\n",
    "\n",
    "    cluster_k = [X[labels==k,:] for k in cluster_vals]\n",
    "\n",
    "    centroids = [torch.mean(k, axis = 0) for k in cluster_k]\n",
    "    cent_dict = dict(zip(cluster_vals,centroids))\n",
    "\n",
    "    variances = [torch.mean(torch.stack([torch.dist(p, centroids[i]) for p in k])) for i, k in enumerate(cluster_k)]\n",
    "    var_dict = dict(zip(cluster_vals,variances))\n",
    "\n",
    "    db = torch.empty((n_cluster,n_cluster)).to(device)\n",
    "    eps = 1e-10 #for stability in denominator\n",
    "\n",
    "    for i,k1 in enumerate(cluster_vals):\n",
    "        for j,k2 in enumerate(cluster_vals):\n",
    "            if (k1 != k2) & (i > j):\n",
    "                result = (var_dict[k1] + var_dict[k2]) / (torch.dist(cent_dict[k1], cent_dict[k2]) + eps)\n",
    "                db[i,j] = result\n",
    "                db[j,i] = result\n",
    "                \n",
    "    result = torch.sum(torch.max(db,dim=0).values) / n_cluster\n",
    "    if result > 10:\n",
    "        return db\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "print_every = 1\n",
    "log_every = 10\n",
    "batch_size = 100\n",
    "\n",
    "losses = []\n",
    "separation_losses = []\n",
    "epoch_losses = [1e12]\n",
    "log.info('Beginning run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7bc7c92400ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdavies_bouldin_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdot_y_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "while(x < 10):\n",
    "    x = davies_bouldin_torch(dot_emb,dot_y_sample)\n",
    "    print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2557e+10, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.max(x,dim=0).values) / len(set(dot_y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.5185e+00, 7.0466e+00, 9.8232e+00, 6.3740e+00, 8.1572e+00, 7.6526e+00,\n",
       "        6.2703e+00, 9.8232e+00, 5.7988e+00, 5.8477e+00, 6.3327e+00, 5.0389e+00,\n",
       "        5.6420e+00, 7.3161e+00, 6.1348e+00, 9.4889e-01, 3.8429e+00, 5.8048e+00,\n",
       "        4.8761e+00, 8.0756e+00, 8.5401e+00, 1.0237e+01, 8.3883e+00, 6.8071e+00,\n",
       "        5.1875e+00, 5.3816e+00, 1.0237e+01, 9.2545e+00, 7.6173e+00, 7.6976e+00,\n",
       "        8.1722e+00, 8.6940e+00, 8.5247e+00, 4.0819e+00, 5.2448e+00, 4.9542e+00,\n",
       "        6.5773e+00, 6.2157e+00, 6.1479e+00, 5.7605e+00, 5.9457e+00, 6.8397e+00,\n",
       "        8.5699e+00, 7.6187e+00, 5.9659e+00, 1.1747e+01, 1.1747e+01, 6.9087e+00,\n",
       "        3.5392e+00, 4.6061e+00, 6.9007e+00, 7.1450e+00, 4.8003e+00, 6.3702e+00,\n",
       "        6.1116e+00, 5.2164e+00, 5.1635e+00, 5.3191e+00, 4.2879e+00, 4.6119e+00,\n",
       "        4.8052e+00, 5.3459e+00, 5.3161e+00, 4.6833e+00, 6.9087e+00, 4.6230e+00,\n",
       "        6.6663e+00, 3.9963e+00, 3.6419e+00, 6.5071e+00, 3.1825e+00, 6.2579e+00,\n",
       "        5.7861e+00, 4.1202e+00, 6.0080e+00, 4.9089e+00, 5.5441e+00, 6.6352e+00,\n",
       "        7.6122e+00, 9.0152e+00, 5.6631e+00, 6.7321e+00, 4.9120e+00, 6.0630e+00,\n",
       "        5.3388e+00, 4.2250e+00, 4.5190e+00, 7.6855e+00, 5.3035e+00, 7.6232e+00,\n",
       "        6.6249e+00, 3.9756e+00, 1.2055e+12, 8.0485e+00, 8.8165e+00, 4.5257e+00],\n",
       "       device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.max(x,dim=0).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0124e+00, 4.1063e+00, 4.2540e+00, 3.1399e+00, 4.5659e+00, 3.7391e+00,\n",
       "        5.1167e+00, 4.2183e+00, 3.9941e+00, 4.0391e+00, 3.7449e+00, 3.8253e+00,\n",
       "        4.3522e+00, 4.9452e+00, 3.8664e+00, 5.1861e-01, 2.5564e+00, 3.5367e+00,\n",
       "        3.6317e+00, 4.3446e+00, 4.7764e+00, 4.5923e+00, 3.8808e+00, 3.7931e+00,\n",
       "        3.9228e+00, 3.4028e+00, 4.3385e+00, 5.1962e+00, 3.8609e+00, 3.4550e+00,\n",
       "        4.2699e+00, 4.1593e+00, 3.8741e+00, 3.1816e+00, 3.3466e+00, 4.1650e+00,\n",
       "        3.1915e+00, 4.0601e+00, 4.3805e+00, 3.8387e+00, 4.6269e+00, 4.2284e+00,\n",
       "        4.3432e+00, 3.9235e+00, 4.8593e+00, 3.7482e+00, 3.9754e+00, 3.9658e+00,\n",
       "        2.4308e+00, 3.1205e+00, 3.3779e+00, 3.9723e+00, 3.5346e+00, 4.3675e+00,\n",
       "        3.6935e+00, 4.2207e+00, 2.8819e+00, 3.0272e+00, 2.8649e+00, 3.3688e+00,\n",
       "        3.6996e+00, 3.8036e+00, 2.8774e+00, 2.9437e+00, 3.5333e+00, 2.5526e+00,\n",
       "        3.3414e+00, 3.4850e+00, 2.7428e+00, 4.4995e+00, 2.7847e+00, 4.1063e+00,\n",
       "        3.2932e+00, 3.4955e+00, 3.3841e+00, 2.5952e+00, 3.7869e+00, 3.9746e+00,\n",
       "        4.6641e+00, 4.5974e+00, 3.4946e+00, 4.8428e+00, 3.6344e+00, 4.4476e+00,\n",
       "        3.6397e+00, 3.5831e+00, 2.6160e+00, 5.4637e+00, 3.8526e+00, 5.6138e+00,\n",
       "        4.1661e+00, 2.3303e+00, 1.2055e+12, 7.2066e+00, 8.8165e+00, 2.4085e+00],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "separation avg loss: 7.000402\n",
      "star avg loss: 51795970.0\n",
      "separation avg loss: 6.9682403\n",
      "star avg loss: 46705896.0\n",
      "separation avg loss: 6.9587893\n",
      "star avg loss: 40460550.0\n",
      "separation avg loss: 6.9912186\n",
      "star avg loss: 41930256.0\n",
      "separation avg loss: 6.9734917\n",
      "star avg loss: 39674980.0\n",
      "separation avg loss: 6.9584804\n",
      "star avg loss: 37835556.0\n",
      "separation avg loss: 6.9364424\n",
      "star avg loss: 36274220.0\n",
      "separation avg loss: 6.998781\n",
      "star avg loss: 35051616.0\n",
      "separation avg loss: 7.0450826\n",
      "star avg loss: 33512200.0\n",
      "separation avg loss: 7.0136743\n",
      "star avg loss: 32475740.0\n",
      "separation avg loss: 6.98145\n",
      "star avg loss: 28773114.0\n",
      "separation avg loss: 6.9661016\n",
      "star avg loss: 26405724.0\n",
      "separation avg loss: 6.9493346\n",
      "star avg loss: 25643678.0\n",
      "separation avg loss: 6.905468\n",
      "star avg loss: 22514270.0\n",
      "separation avg loss: 6.8607855\n",
      "star avg loss: 21299674.0\n",
      "separation avg loss: 6.8437386\n",
      "star avg loss: 20470024.0\n",
      "separation avg loss: 6.8279486\n",
      "star avg loss: 19032980.0\n",
      "separation avg loss: nan\n",
      "star avg loss: 17737832.0\n",
      "sep loss issue: tensor(4.3843e+33, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "you've got nans\n"
     ]
    }
   ],
   "source": [
    "#Real loop\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(len(train_pos)).numpy()\n",
    "    nan_break = False\n",
    "    \n",
    "    for i in range(0,len(train), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch = train_pos[indices]\n",
    "\n",
    "        model.train(); opt.zero_grad()\n",
    "\n",
    "        l_batch, r_batch, neg_batch = model(batch)\n",
    "        \n",
    "        # nan tests...\n",
    "        l_test = np.isnan(np.mean(l_batch.detach().cpu().numpy()))\n",
    "        r_test = np.isnan(np.mean(r_batch.detach().cpu().numpy()))\n",
    "        neg_test = np.isnan(np.mean(neg_batch.detach().cpu().numpy()))\n",
    "        if l_test or r_test or neg_test:\n",
    "            nan_break = True\n",
    "            break\n",
    "        \n",
    "        positive_similarity = torch.bmm(l_batch,r_batch.transpose(2,1))\n",
    "        negative_similarity = torch.bmm(l_batch, neg_batch.transpose(2,1)).squeeze(1)\n",
    "\n",
    "        star_loss = torch.sum(torch.clamp(.1 - positive_similarity + negative_similarity, min=0))\n",
    "        \n",
    "        # Now add in clustering loss for DOT categories\n",
    "        idx = np.random.choice(len(dot_positions),5000)\n",
    "        dot_sample = dot_positions[idx]\n",
    "        dot_y_sample = dot_labs[idx].reset_index(drop=True)\n",
    "        \n",
    "        dot_emb = torch.empty([len(dot_sample),100],requires_grad=True).to(device)\n",
    "        for j,doc in enumerate(dot_sample):\n",
    "            doc_flat = torch.cat([torch.unsqueeze(z,0) for z in doc],1).squeeze(0).to(device)\n",
    "            dot_emb[j] = model.embed_doc(doc_flat)\n",
    "\n",
    "        separation_loss = davies_bouldin_torch(dot_emb,dot_y_sample)\n",
    "        if separation_loss > 10:\n",
    "            print('sep loss issue: %s' % str(separation_loss))\n",
    "            nan_break = True\n",
    "            break\n",
    "        \n",
    "        #Combine losses\n",
    "        loss = star_loss + separation_loss\n",
    "\n",
    "        loss.backward();opt.step()\n",
    "\n",
    "        losses.append(star_loss.detach().cpu().numpy())\n",
    "        separation_losses.append(separation_loss.detach().cpu().numpy())\n",
    "\n",
    "        if i % (print_every*batch_size) == 0:\n",
    "            print('separation avg loss: %s' % str(np.mean(separation_losses[-10:])))\n",
    "            print('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "        if i % (log_every*batch_size) == 0:\n",
    "            log.info('separation avg loss: %s' % str(np.mean(separation_losses[-10:])))\n",
    "            log.info('star avg loss: %s' % str(np.mean(losses[-10:])))\n",
    "    \n",
    "    # End of inner loop\n",
    "    if nan_break:\n",
    "        print(\"you've got nans\")\n",
    "        log.warning(\"you've got nans\")\n",
    "        break\n",
    "    \n",
    "    print('Finished epoch %s at %s.' % (epoch,time.ctime()))\n",
    "    log.info(\"Finished epoch %s\" % str(epoch))\n",
    "    \n",
    "    epoch_loss = np.mean(losses[(len(losses)-100):])\n",
    "    \n",
    "    if epoch_loss < min(epoch_losses):\n",
    "        print('best epoch so far!')\n",
    "        log.info('best epoch so far!')\n",
    "        \n",
    "        weights = model.embeddings.weight\n",
    "        with open(OUTPUT_WEIGHTS + 'weights_best_epoch', 'wb') as f:\n",
    "            pickle.dump(weights.data.detach().cpu().numpy(), f)\n",
    "    \n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.embeddings.weight\n",
    "with open(OUTPUT_WEIGHTS + 'weights_%s' % SAMPLE_SIZE, 'wb') as f:\n",
    "    pickle.dump(weights.data.detach().cpu().numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('You made it!')\n",
    "log.info('You made it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the weights to CSV\n",
    "# weights = model.input_embedding.weight\n",
    "# weights = weights.data.detach().numpy()\n",
    "# np.savetxt(\"weights_%s.csv\" % SAMPLE_SIZE, weights, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
